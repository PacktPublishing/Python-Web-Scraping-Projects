url,title,location,job_type,posted_date,saved_times,description,views,unique_views,about_you,your_role,requirements,nice_to_have,why_work_with_us,desired_skills,contact
https://www.remotepython.com/jobs/a3fb0a06b12d4e9fa7289a5f3f4eede4/,"Part-time, Remote Scrapy Engineer","Local Insights, San Francisco, California, United States","Part-time
                      
                          Contract","Aug. 17, 2017",11,"Hi, we are looking for engineers to join our growing team of big data professionals. If you're succesful, you'll join the long term team that is already in place.Important: we're using scrapy and these jobs are pretty straightforward. It should only take 1-2 hours to complete the job.Requirements: - You speak english very well - You are great with Python 3.X - You're a Scrapy expert - You've worked with multi-threading - You're well experienced with Postgresql - You use Git and have worked with github or bitbucket - You only code in a non-windows environment - Linux, Unix, Mac - You know how to abstract and modularize your code - You write clean and performant code - You know how to deal with error handling and waits - You can deal with timeouts - You know how to beat anti-bot protections - You have worked with captchas - You have worked with proxy servers - You like to work in distributed teams - You have done code reviewAdditional skills useful but not required: - You want to grow into a full-time position - You want to work on the web app - You want to grow and learn new skills - You work fast and efficiently - You want to contribute to our framework and make it better!Perks: - you'll get to join a global team of talented but down to earth people - you'll build new skills and own your code - you'll grow your skillset and learn things - You can grow with the organization and move into other rolesIf you meet the requirements, please apply here: https://docs.google.com/a/localinsights.io/forms/d/112qf9tRbxXcPynT-AH4lcUhnnwerh-HW9_EX2OBqGg0","1,414","2,109",[],[],[],[],[],"['Git', 'Linux', 'PostgreSQL', 'Scrapy', 'Web Scraping']",['Company Website: https://localinsights.io/']
https://www.remotepython.com/jobs/9ff6736dc9eb4123abc91443021838cc/,Python Developer (Web Scraping),"Scrapinghub, Cork, Ireland",,"Aug. 22, 2017",15,"Scrapinghub is looking for software engineers to join our Professional Services team to work on web crawler development with Scrapy, our flagship open source project.Are you interested in building web crawlers harnessing the Scrapinghub platform, which powers crawls of over 3 billion pages a month? Do you like working in a company with a strong open source foundation? Scrapinghub helps companies, ranging from Fortune 500 enterprises to up and coming early stage startups, turn web content into useful data with a cloud-based web crawling framework, off-the-shelf datasets, and turn-key web scraping services.Join us in making the world a better place for web crawler developers with our team of top talented engineers working remotely from more than 30 countries.RESPONSIBILITIESScrapinghub's platform and Professional Services offerings have been growing tremendously over the past couple of years but there are a lot of big projects waiting in the pipeline, and in this role you would be a key part of that process. Here's what we're looking for: WHAT YOU GETScrapinghub is a startup with the goal of providing the best web scraping technology.We currently provide services for running Scrapy web crawlers, storing and searching crawled data, visualizing the crawl process, automatic information extraction (based on supervised learning) and a proxy network for routing requests. We also develop open source libraries for web crawling and information extraction.Our clients are from a diverse range of industries, they're usually technical and build very interesting products with the data and services we provide.This is an opportunity to join at an early stage where you can have a huge impact on the success of the company.","1,758","3,118",[],[],[],[],[],"['JavaScript', 'Linux', 'Pandas', 'Scrapy', 'Web Scraping']",['Company Website: https://scrapinghub.com/']
https://www.remotepython.com/jobs/88e1e53295964e9b8f222d0d7de68aa7/,Web Scraping Engineer - Remote Contract,"Lyst, London, United Kingdom",Contract,"May 26, 2018",8,"Lyst is a technology platform that revolutionises the way people shop for fashion. We connect millions of consumers globally with the world’s leading fashion designers and stores, giving them a simpler, more engaging and more effective shopping experience. Lyst has grown over 300% every year since launch in 2011 and has raised over $60M from top-tier investors including Accel, DFJ, Balderton and the teams behind LVMH, Michael Kors and Oscar de la Renta.Lyst are looking to engage full stack python and javascript developers to work on our Retailer Integrations team. You’ll work on our web scraping architecture; building spiders and maintaining integrations with our partners across the world. This is a contract role, we are looking for people that can commit a minimum of 40 hours a week and the rate is €15 an hour.Our remote web crawling team is one of Lyst’s best kept secrets, this remote team supports and assists the onboarding of our new partners across the globe. Working closely with our Partner Integrations team and large engineering team here in London, you will be building the scrapers (spiders) that push new products, stock availability and price changes automatically on to Lyst's platform.Our spiders are written in Python using the Scrapy framework, with javascript on the front-end. We are working on projects that improve infrastructure, automate common tasks, improve our understanding of the data, system vital signs and the fashion world. The team communicates on Slack and we use Jira to help us manage the tasks and deliver work on time. You can find out a lot more about how we work and more of the projects we work on here: developers.lyst.comWe’re looking for engineers who are excited by the technical problems that Lyst faces as we grow and are interested in working on the huge challenges we are facing.ExperienceUsing Python in a production environment Working as part of a remote team Working on large web applications Working in an English speaking environment Ideal experienceExperience writing web scrapers, (Ideally in Scrapy) Understanding of front end architecture Working with productivity tools like Jira, Confluence, and SlackYou will be challenged, supported and have the opportunity to learn a lot. You will work in a fast paced, autonomous environment with like minded people who are passionate about what they do. Your willingness to learn and your ability to suggest improvements will allow you to grow as Lyst does and become a key member of our team.We care deeply about helping the tech industry become a more inclusive and diverse place and we work hard to lead by example. Our workplace is dynamic, diverse and highly collaborative. You will join a huge multinational team of engineers based across multiple time zones that love to work with each other and meet up from time to time.All your information will be kept confidential according to EEO guidelines.","1,903","2,881",[],[],[],[],[],"['Fullstack Development', 'JavaScript', 'Scrapy', 'Web Scraping']",['Company Website: http://www.lyst.com/']
https://www.remotepython.com/jobs/4e04ffe2bef04340b85560945fba95c8/,"Back End Developer, Web Scrapping, Data Science","Pathfinder Software, London, United Kingdom",Full-time,"Dec. 3, 2017",2,"Pathfinder is an innovative career intelligence tool. Simplicity combined with the power and data quality of expensive financial platforms. Pathfinder will accompany users through the defining years when deciding, planning, competing, and realising their career paths, as well as developing and progressing in their chosen fields. Pathfinder has partnered with major data providers to complement our product, we are also part of Microsoft’s prestigious BizSpark Plus Program. We have raised seed funding and are fortunate to have prominent professional advisors on board. We tested our initial product with users in November and we are ready to continue to the next stage of product development.Pathfinder is looking for a bright and experienced Back-End Developer with a hunger to create and develop a global product. The developer must be ready to take a range of responsibilities involving all stages of the software lifecycle.Required Experience: - Fluency in Python / Django - Web scrapping technologies (including Scrapy and scrapinghub.com) - PostgreSQL and MySQL - Elastic Search - Git - Data science practice- dealing with messy data, creating and working with databases containing millions of records, and generating automated testsDesired, Not Necessary: - Keras, TensorFlow, Caffe, or mxnet - Program asyncronous and/or multiprocess codeThe successful candidate will join an intimate and high-achieving team as a core, founding member. Emphasis will be given to adherence to deadlines, efficiency and effectiveness when producing work, and consistent dedication to produce output. This opportunity has no limits in terms of progression and development.Please do apply to find out more about the role and the firm.","1,111","1,696",[],[],[],[],[],"['Backend Development', 'Data Science', 'Django', 'Elasticsearch', 'Git', 'MySQL', 'PostgreSQL', 'Scrapy', 'Web Scraping']",['Company Website: http://www.pathfinder-software.com/']
https://www.remotepython.com/jobs/1a576ae3e6d24f65b39b51da597ae184/,Python Developer in Test,Scrapinghub,Full-time,"Jan. 19, 2018",4,"QA is an important function within Scrapinghub. The QA team works to ensure that the quality and usability of the data scraped by our web scrapers meets and exceeds the expectations of our enterprise clients.Are you passionate about data and data quality and integrity?Do you enjoy using Python to automate testing, analyze data, and speed up manual processes?Are you highly customer-focused with excellent attention to detail?Due to growing business and the need for ever more sophisticated QA, we are looking for talented Software Engineers with experience in Python and automation to join our team.  As a Scrapinghub Engineer, you will build automated test frameworks and ad hoc test scripts to assist verification and validation of data quality.Due to business requirements, candidates must be based in a European or U.S. timezone.",843,"1,313",[],[],[],[],[],"['JavaScript', 'Linux', 'Scrapy', 'Web Scraping']",['Company Website: https://scrapinghub.com/']
https://www.remotepython.com/jobs/461c135809d14c1d9d90a72a8baa0c3c/,Backend Engineer,Voltus,Full-time,"June 17, 2018",3,"Voltus is looking for an experienced backend engineer to help us process and present the data from our growing network of smart meters. The thought of building out integrations with different components of the North American electric grid is exciting. You know how to write a beautiful API—and you know how to shim an ugly one. You will be responsible for building secure bridges from our (beautiful! modern!) internal systems to external systems that can only be viewed on IE8. Anyone can integrate to a webhook, but it takes a pro to ingest data over SCADA. Like all of your Voltus teammates, you are bright, gritty, and good.## Key Responsibilities- Develop the application and API layers for customer-facing and internal tools to process our ever-growing pile of electricity demand data and market intelligence - Help build the outermost layer of the Voltus network, interfacing to a wide variety of electric industry partners - Build creative shims to legacy systems—everyone loves a clean API, but not everyone can scrape an ActiveX application from 1997 - Build out the systems that to connect sensor data to internal and customer-facing tools and applications - Process, clean, validate, and present data from sensor to customer dashboard in real-time (no sweat!)## Technologies we use: - Python, Javascript, Go, Lua - Postgres, Redis, S3, Kafka, InfluxDB - AWS, Docker - React, Flask, Scrapy - Pandas, NumPy","1,054","1,631",[],[],[],[],[],"['Amazon Web Services', 'Backend Development', 'Docker', 'Flask', 'JavaScript', 'NumPy', 'Pandas', 'PostgreSQL', 'ReactJS', 'Redis', 'Scrapy', 'SQLAlchemy']",['Company Website: http://voltus.co/']
https://www.remotepython.com/jobs/798ee34b73174ffcbbc1442c0576c25e/,Data Science / Programming Intern,"Snapwiz, Fremont, California, United States",Internship,"May 16, 2017",15,"We work on the domains of education, knowledge acquisition, adaptive learning, professional development, skill mastery and skill networks. Be part of a fun and cool company that is not too big so you can easily see the impact of your contributions.We are staffing for internships for Summer 2018. You should be proficient in data munging in either R or Python with some background or willingness to learn web scraping (experience with Scrapy (pyhton), httr/rvest), XML or JSON manipulation with some text analysis techniques would be most beneficial.","1,778","2,599",[],[],[],[],[],"['Data Science', 'Web Scraping']",['Company Website: http://www.snapwiz.com/']
https://www.remotepython.com/jobs/654bd71875054e91af14c6d763241eb7/,Python Software Engineer [Clean Energy Job],"UtilityAPI, Oakland, CA, United States",Full-time,"July 25, 2017",3,"==Job Description==UtilityAPI (https://utilityapi.com) is a software platform that is used by solar and energy efficiency companies to collect their customer's utility bill and usage data automatically. You will be writing application code and helping maintain/optimize/scale the python stack. We write scripts that collect data from utilities, and these scripts can break unexpectedly when utilities change their interfaces, so being able to update them quickly is important. Our codebase (python, django, celery) is well organized, documented, and tested. You are welcome to work remotely in the United States or in our office in downtown Oakland, CA.SALARY: $60k - $80k depending on experienceREMOTE WORK: OK (U.S. Only)==Requirements==* U.S. Citizen, Permanent Resident, or non-expiring Visa not requiring sponsorship* At least 1 year of Python work experience, and in-depth knowledge of Python Language* HTTP (methods, cookies, headers, etc.)* Regular Expressions (we use them heavily)* CSS Selectors (we use them heavily)* JavaScript (basic understanding)* Git, SSH, GPG (basic understanding)==Preferred==* Experience with web scraping tools such as Selenium, Scrapy, Mechanize, etc.==How To Apply==Apply here: http://goo.gl/forms/YICrUuz7XNjiTcId2Apply here: http://goo.gl/forms/YICrUuz7XNjiTcId2",529,972,[],[],[],[],[],"['Celery', 'Django']","['Contact Name: Daniel Roesler', 'Contact Email: daniel@utilityapi.com', 'Company Website: https://utilityapi.com']"
